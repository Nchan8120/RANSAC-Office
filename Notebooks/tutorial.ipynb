{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbea777",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5bfab026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 1. Library setup\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f4d30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATANAME = \"ITC_groundfloor.ply\"\n",
    "pcd = o3d.io.read_point_cloud(\"../Data/\" + DATANAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "223ea0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 334992 points.\n",
      "Number of points: 334992\n",
      "First 5 points:\n",
      " [[2.55192887e+05 4.73200869e+05 3.05235004e+01]\n",
      " [2.55192988e+05 4.73200812e+05 3.05227509e+01]\n",
      " [2.55193038e+05 4.73200783e+05 3.05232506e+01]\n",
      " [2.55192937e+05 4.73200840e+05 3.05249996e+01]\n",
      " [2.55192985e+05 4.73200872e+05 3.05240002e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Print basic info\n",
    "print(pcd)\n",
    "\n",
    "# Print number of points\n",
    "print(\"Number of points:\", np.asarray(pcd.points).shape[0])\n",
    "\n",
    "# Show the first few points\n",
    "print(\"First 5 points:\\n\", np.asarray(pcd.points)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ac0431b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcd_center: [2.55203955e+05 4.73205983e+05 3.21217287e+01]\n",
      "Type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# shift point cloud to bypasss large coordinates approxximation\n",
    "pcd_center = pcd.get_center()\n",
    "print(\"pcd_center:\", pcd_center)\n",
    "print(\"Type:\", type(pcd_center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f88f0554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 334992 points."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd.translate(-pcd_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7cf4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca703a98",
   "metadata": {},
   "source": [
    "### Random Sampling\n",
    "At the matrix level, the decimation acts by keeping points for every n-th row depending on the n factor. Of course, this is made based on how the points are stored in the file. Slicing a point cloud with open3d It is pretty straightforward. To shorten and parametrize the expression, you can write the lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a78e3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_ratio = 0.2 # keep 20% of the points\n",
    "sampled_pcd = pcd.random_down_sample(retained_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab29190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sampled point cloud\n",
    "o3d.visualization.draw_geometries([sampled_pcd], window_name = \"Random Sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb30da",
   "metadata": {},
   "source": [
    "### Statistical outlier removal\n",
    "Using an outlier filter on 3D point cloud data can help identify and remove any data points significantly different from the rest of the dataset. These outliers could result from measurement errors or other factors that can skew the analysis. By removing these outliers, we can get a more valid representation of the data and better adjust algorithms. However, we need to be careful not to delete valuable points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ad9f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 16 # How many neightbors are considered to calculate the averate distance for a given point\n",
    "std_multiplier = 10 # threshold based on standard deviation. the lower the number, the more aggressive the filter will be\n",
    "\n",
    "filtered_pcd, filtered_idx = pcd.remove_statistical_outlier(nn, std_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17e7b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colour outliers in red\n",
    "outliers = pcd.select_by_index(filtered_idx, invert=True)\n",
    "outliers.paint_uniform_color([1, 0, 0])\n",
    "o3d.visualization.draw_geometries([filtered_pcd, outliers])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4983f68e",
   "metadata": {},
   "source": [
    "### Point Cloud Voxel Sampling\n",
    "The grid subsampling strategy is based on the division of the 3D space in regular cubic cells called voxels. For each cell of this grid, we only keep one representative point, and this point, the representative of the cell, can be chosen in different ways. When subsampling, we keep that cell's closest point to the barycenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "447715cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = 0.05\n",
    "pcd_downsampled = filtered_pcd.voxel_down_sample(voxel_size = voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "79fa1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_downsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8815c5",
   "metadata": {},
   "source": [
    "### Normals extraction\n",
    "A point cloud normal refers to the direction of a surface at a specific point in a 3D point cloud. It can be used for segmentation by dividing the point cloud into regions with similar normals, for example. In our case, normals will help identify objects and surfaces within the point cloud, making it easier to visualize. And it is an excellent opportunity to introduce a way to compute such normals semi-automatically. We first define the average distance between each point in the point cloud and its neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e473a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_distance = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951fe52",
   "metadata": {},
   "source": [
    "Then we use this information to extract a limited max_nn points within a radius radius_normals to compute a normal for each point in the 3D point cloud:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f0878ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_normals=nn_distance*4\n",
    "pcd_downsampled.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normals, max_nn=16), fast_normal_computation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8c660900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_downsampled.paint_uniform_color([0.6, 0.6, 0.6])\n",
    "o3d.visualization.draw_geometries([pcd_downsampled,outliers])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4c8225",
   "metadata": {},
   "source": [
    "### RANSAC\n",
    "The RANSAC algorithm, short for RANdom SAmple Consensus, is a powerful tool for handling data that contains outliers, which is often the case when working with real-world sensors. The algorithm works by grouping data points into two categories: inliers and outliers. By identifying and ignoring the outliers, you can focus on working with reliable inliers, making your analysis more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5808d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_distance = np.mean(pcd.compute_nearest_neighbor_distance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac39cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = 0.1 # max distance a point can be from the plane model, and still be an inlier\n",
    "ransac_n = 3 # number of points to sample for generating a plane model\n",
    "num_iterations = 1000 # number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85876787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane equation: -0.00x + -0.00y + 1.00z + 1.35 = 0\n"
     ]
    }
   ],
   "source": [
    "plane_model, inliers = pcd.segment_plane(distance_threshold=distance_threshold,ransac_n=3,num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb907528",
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_cloud = pcd.select_by_index(inliers)\n",
    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "\n",
    "#Paint the clouds\n",
    "inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "outlier_cloud.paint_uniform_color([0.6, 0.6, 0.6])\n",
    "\n",
    "#Visualize the inliers and outliers\n",
    "o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984be23",
   "metadata": {},
   "source": [
    "### Scaling 3D: Multi-Order RANSAC\n",
    "Our philosophy will be very simple. We will first run RANSAC multiple times (let say n times) to extract the different planar regions constituting the scene. Then we will deal with the “floating elements” through Euclidean Clustering (DBSCAN). It means that we have to make sure we have a way to store the results during iterations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1c5b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionary to hold results of iterations\n",
    "segment_models={} # Plane parameters\n",
    "segments={} # Planar regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a5acc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_plane_idx=10 # number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6b85099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass 0 / 10 done.\n",
      "pass 1 / 10 done.\n",
      "pass 2 / 10 done.\n",
      "pass 3 / 10 done.\n",
      "pass 4 / 10 done.\n",
      "pass 5 / 10 done.\n",
      "pass 6 / 10 done.\n",
      "pass 7 / 10 done.\n",
      "pass 8 / 10 done.\n",
      "pass 9 / 10 done.\n"
     ]
    }
   ],
   "source": [
    "# seperate inliers from outliers. Store inliers in segments dictionary.\n",
    "rest=pcd\n",
    "for i in range(max_plane_idx):\n",
    "    colors = plt.get_cmap(\"tab20\")(i)\n",
    "    segment_models[i], inliers = rest.segment_plane(\n",
    "    distance_threshold=0.1,ransac_n=3,num_iterations=1000)\n",
    "    segments[i]=rest.select_by_index(inliers)\n",
    "    segments[i].paint_uniform_color(list(colors[:3]))\n",
    "    rest = rest.select_by_index(inliers, invert=True)\n",
    "    print(\"pass\",i,\"/\",max_plane_idx,\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bf9654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([segments[i] for i in range(max_plane_idx)]+[rest])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c5f1d",
   "metadata": {},
   "source": [
    "### Euclidean Cluster DBSCAN\n",
    "The DBSCAN algorithm involves scanning through each point in the dataset and constructing a set of reachable points based on density. This is achieved by analyzing the neighborhood of each point and including it in the region if it contains enough points. The process is repeated for each neighboring point until the cluster can no longer expand. Points that do not have enough neighbors are labeled as noise, making the algorithm robust to outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b411880",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.15\n",
    "min_cluster_points = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c8010f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nchan\\AppData\\Local\\Temp\\ipykernel_16748\\1254871236.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  best_candidate=int(np.unique(labels)[np.where(candidates== np.max(candidates))[0]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass 0 / 10 done.\n",
      "pass 1 / 10 done.\n",
      "pass 2 / 10 done.\n",
      "pass 3 / 10 done.\n",
      "pass 4 / 10 done.\n",
      "pass 5 / 10 done.\n",
      "pass 6 / 10 done.\n",
      "pass 7 / 10 done.\n",
      "pass 8 / 10 done.\n",
      "pass 9 / 10 done.\n"
     ]
    }
   ],
   "source": [
    "rest=pcd\n",
    "for i in range(max_plane_idx):\n",
    "    colors = plt.get_cmap(\"tab20\")(i)\n",
    "    segment_models[i], inliers = rest.segment_plane(\n",
    "    distance_threshold=0.1,ransac_n=3,num_iterations=1000)\n",
    "    segments[i]=rest.select_by_index(inliers)\n",
    "    labels = np.array(segments[i].cluster_dbscan(eps=epsilon, min_points=min_cluster_points)) # DBSCAN clustering\n",
    "    candidates=[len(np.where(labels==j)[0]) for j in np.unique(labels)]\n",
    "    best_candidate=int(np.unique(labels)[np.where(candidates== np.max(candidates))[0]])\n",
    "    rest = rest.select_by_index(inliers, invert=True) + segments[i].select_by_index(list(np.where(labels!=best_candidate)[0]))\n",
    "    segments[i]=segments[i].select_by_index(list(np.where(labels== best_candidate)[0]))\n",
    "    segments[i].paint_uniform_color(list(colors[:3]))\n",
    "    print(\"pass\",i,\"/\",max_plane_idx,\"done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5291c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([segments[i] for i in range(max_plane_idx)]+[rest])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd0edf",
   "metadata": {},
   "source": [
    "### Euclidean Clusterign Refinement\n",
    "Okay, time to evade the loop, and work on the remaining points assigned to therest variable, that are not yet attributed to any segment. Let us first get a visual grasp on what we are talking about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "654bbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([rest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c4ab807",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(pcd.cluster_dbscan(eps=0.1, min_points=10)) # -1 is noise. 0-n are the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0959eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = labels.max() \n",
    "colors = plt.get_cmap(\"tab20\")(labels / (max_label \n",
    "if max_label > 0 else 1))\n",
    "colors[labels < 0] = 0\n",
    "rest.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "o3d.visualization.draw_geometries([rest])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8dbc53",
   "metadata": {},
   "source": [
    "### Voxel Grid Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c2685de",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef64636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the extents of the point cloud\n",
    "min_bound = pcd.get_min_bound()\n",
    "max_bound = pcd.get_max_bound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96540f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate the segements from RANSAC\n",
    "pcd_ransac=o3d.geometry.PointCloud()\n",
    "for i in segments:\n",
    "    pcd_ransac += segments[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab685e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract voxel grid from the RANSAC segments\n",
    "voxel_grid_structural = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd_ransac, voxel_size=voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82f4b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing for remaining elements\n",
    "rest.paint_uniform_color([0.1, 0.1, 0.8])\n",
    "voxel_grid_clutter = o3d.geometry.VoxelGrid.create_from_point_cloud(rest, voxel_size=voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1da6d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([voxel_grid_clutter,voxel_grid_structural])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bf2e0",
   "metadata": {},
   "source": [
    "### Spacial Modeling\n",
    "In indoor modeling applications, the voxel-based representation of point clouds plays a pivotal role in capturing and analyzing the geometric properties of complex environments. As the scale and complexity of point cloud datasets increase, it becomes essential to delve deeper into voxel segmentation techniques to extract meaningful structures and facilitate higher-level analysis. Let us thus define a function that fits a voxel grid and return both filled and empty spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f4841ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_voxel_grid(point_cloud, voxel_size, min_b=False, max_b=False):\n",
    "    # Determine the minimum and maximum coordinates of the point cloud\n",
    "    if type(min_b) == bool or type(max_b) == bool:\n",
    "        min_coords = np.min(point_cloud, axis=0)\n",
    "        max_coords = np.max(point_cloud, axis=0)\n",
    "    else:\n",
    "        min_coords = min_b\n",
    "        max_coords = max_b\n",
    "        # Calculate the dimensions of the voxel grid\n",
    "        grid_dims = np.ceil((max_coords - min_coords) / voxel_size).astype(int)\n",
    "        # Create an empty voxel grid\n",
    "        voxel_grid = np.zeros(grid_dims, dtype=bool)\n",
    "        # Calculate the indices of the occupied voxels\n",
    "        indices = ((point_cloud - min_coords) / voxel_size).astype(int)\n",
    "        # Mark occupied voxels as True\n",
    "        voxel_grid[indices[:, 0], indices[:, 1], indices[:, 2]] = True\n",
    "    return voxel_grid, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0efe72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid dimensions: [60 47  8]\n"
     ]
    }
   ],
   "source": [
    "min_bound = pcd.get_min_bound()\n",
    "max_bound = pcd.get_max_bound()\n",
    "grid_dims = np.ceil((max_bound - min_bound) / voxel_size).astype(int)\n",
    "print(\"Grid dimensions:\", grid_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voxel_size = 0.3\n",
    "\n",
    "#get the bounds of the original point cloud\n",
    "min_bound = pcd.get_min_bound()\n",
    "max_bound = pcd.get_max_bound()\n",
    "\n",
    "ransac_voxels, idx_ransac = fit_voxel_grid(pcd_ransac.points, voxel_size, min_bound, max_bound)\n",
    "rest_voxels, idx_rest = fit_voxel_grid(rest.points, voxel_size, min_bound, max_bound)\n",
    "\n",
    "#Gather the filled voxels from RANSAC Segmentation\n",
    "filled_ransac = np.transpose(np.nonzero(ransac_voxels))\n",
    "\n",
    "#Gather the filled remaining voxels (not belonging to any segments)\n",
    "filled_rest = np.transpose(np.nonzero(rest_voxels))\n",
    "\n",
    "#Compute and gather the remaining empty voxels\n",
    "total = pcd_ransac + rest\n",
    "total_voxels, idx_total = fit_voxel_grid(total.points, voxel_size, min_bound, max_bound)\n",
    "empty_indices = np.transpose(np.nonzero(~total_voxels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ad0d7",
   "metadata": {},
   "source": [
    "### Exporting 3D Datasets\n",
    " To visualize the results as shown below outside of Python with transparency, we need to export our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "959129f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PointCloud with 105394 points.\n",
      "1 PointCloud with 47753 points.\n",
      "2 PointCloud with 28127 points.\n",
      "3 PointCloud with 28063 points.\n",
      "4 PointCloud with 11019 points.\n",
      "5 PointCloud with 10944 points.\n",
      "6 PointCloud with 18028 points.\n",
      "7 PointCloud with 2988 points.\n",
      "8 PointCloud with 4777 points.\n",
      "9 PointCloud with 5763 points.\n"
     ]
    }
   ],
   "source": [
    "# export the segmented point cloud.\n",
    "xyz_segments=[]\n",
    "for idx in segments:\n",
    " print(idx,segments[idx])\n",
    " a = np.asarray(segments[idx].points)\n",
    " N = len(a)\n",
    " b = idx*np.ones((N,3+1))\n",
    " b[:,:-1] = a\n",
    " xyz_segments.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cc88e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the remaining elements from DBSCAN\n",
    "rest_labels = labels[-len(rest.points):]  # Use only the last N labels if rest is the last segment\n",
    "rest_w_segments = np.hstack((np.asarray(rest.points), (rest_labels + max_plane_idx).reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d09b4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_segments.append(rest_w_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e46c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../Results/\" + DATANAME.split(\".\")[0] + \".xyz\", np.concatenate(xyz_segments), delimiter=\";\", fmt=\"%1.9f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28026223",
   "metadata": {},
   "source": [
    "### Voxel Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be6c779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function created by F. Poux, License MIT.\n",
    "#Please cite to reuse in your project\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cube(c, s, compteur=0):\n",
    "    \"\"\"\n",
    "    Generate vertices and faces for a cube.\n",
    "\n",
    "    Parameters:\n",
    "        c (numpy.ndarray): The center point of the cube.\n",
    "        s (float): The side length of the cube.\n",
    "        compteur (int, optional): Offset factor for the face indices. Default is 0.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array containing vertex and face information.\n",
    "\n",
    "    The function calculates the vertices and faces of a cube based on the center point (c),\n",
    "    side length (s), and an optional compteur value for face offset. It constructs the\n",
    "    vertices of the cube, defines the face vertices, assigns labels to the vertices and faces,\n",
    "    and then combines them into an array representing the cube.\n",
    "\n",
    "    Note: This function assumes that numpy has been imported as np.\n",
    "\n",
    "    Example:\n",
    "        center = np.array([0, 0, 0])\n",
    "        side_length = 1.0\n",
    "        cube_array = cube(center, side_length)\n",
    "        print(cube_array)\n",
    "    \"\"\"\n",
    "    # Calculate vertices of the cube\n",
    "    v1 = c + s / 2 * np.array([-1, -1, 1])\n",
    "    v2 = c + s / 2 * np.array([1, -1, 1])\n",
    "    v3 = c + s / 2 * np.array([-1, 1, 1])\n",
    "    v4 = c + s / 2 * np.array([1, 1, 1])\n",
    "    v5 = c + s / 2 * np.array([-1, 1, -1])\n",
    "    v6 = c + s / 2 * np.array([1, 1, -1])\n",
    "    v7 = c + s / 2 * np.array([-1, -1, -1])\n",
    "    v8 = c + s / 2 * np.array([1, -1, -1])\n",
    "\n",
    "    # Define face vertices\n",
    "    f1 = np.array([1, 2, 3])\n",
    "    f2 = np.array([3, 2, 4])\n",
    "    f3 = np.array([3, 4, 5])\n",
    "    f4 = np.array([5, 4, 6])\n",
    "    f5 = np.array([5, 6, 7])\n",
    "    f6 = np.array([7, 6, 8])\n",
    "    f7 = np.array([7, 8, 1])\n",
    "    f8 = np.array([1, 8, 2])\n",
    "    f9 = np.array([2, 8, 4])\n",
    "    f10 = np.array([4, 8, 6])\n",
    "    f11 = np.array([7, 1, 5])\n",
    "    f12 = np.array([5, 1, 3])\n",
    "\n",
    "    # Calculate vertex and face labels\n",
    "    vcube = [v1, v2, v3, v4, v5, v6, v7, v8]\n",
    "    ch = np.empty([8, 1], dtype=str)\n",
    "    ch.fill('v')\n",
    "    vertice = np.hstack((ch, vcube))\n",
    "\n",
    "    faces = [f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12]\n",
    "    faces = np.asarray(faces) + compteur * 8\n",
    "    ch = np.empty([12, 1], dtype=str)\n",
    "    ch.fill('f')\n",
    "    faces = np.hstack((ch, faces))\n",
    "\n",
    "    # Combine vertices and faces\n",
    "    cube = np.append(vertice, faces, axis=0)\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a192fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxel_modelling(filename, indices, voxel_size):\n",
    "    voxel_assembly=[]\n",
    "    with open(filename, \"a\") as f:\n",
    "        cpt = 0\n",
    "        for idx in indices:\n",
    "            voxel = cube(idx,voxel_size,cpt)\n",
    "            f.write(f\"o {idx}  \\n\")\n",
    "            np.savetxt(f, voxel,fmt='%s')\n",
    "            cpt += 1\n",
    "            voxel_assembly.append(voxel)\n",
    "    return voxel_assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55c2b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrsac = voxel_modelling(\"../RESULTS/ransac_vox.obj\", filled_ransac, 1)\n",
    "vrest = voxel_modelling(\"../RESULTS/rest_vox.obj\", filled_rest, 1)\n",
    "vempty = voxel_modelling(\"../RESULTS/empty_vox.obj\", empty_indices, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba137767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RANSAC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
